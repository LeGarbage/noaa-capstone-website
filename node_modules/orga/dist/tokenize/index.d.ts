import { Reader } from 'text-kit';
import { Point, Position } from 'unist';
import type { LexerOptions } from '../options.js';
import { Token } from '../types.js';
export interface Lexer {
    eat: (type?: string) => Token | undefined;
    eatAll: (type: string) => number;
    peek: (offset?: number) => Token | undefined;
    match: (cond: RegExp | string, offset?: number) => boolean;
    all: () => Token[];
    save: () => number;
    restore: (point: number) => void;
    addInBufferTodoKeywords: (text: string) => void;
    substring: (position: Position) => string;
    /** Modify the next token (or the token at the given offset). */
    modify(f: (t: Token) => Token, offset?: number): void;
    readonly now: number;
    toOffset: (point: Point | number) => number;
    toPoint: (point: number) => Point;
}
export type Tokenizer = (reader: Reader) => Token[] | Token | void;
export declare const tokenize: (text: string, options: LexerOptions) => Lexer;
